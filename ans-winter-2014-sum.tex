\documentclass{anstrans}

\usepackage{url}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{PyNE Progress Report 2.0} 
\author{Cameron~R.~Bates$^{1,2}$, Elliott~Biondo$^{3}$, Kathryn~Huff$^{2}$ Anthony~Scopatz$^{3}$, ....}

\institute{

$^{1}$ Lawrence Livermore National Laboratory, 7000 East Ave L-188, Livermore, CA 94550, USA \\
\and $^{2}$ The University of California, Berkeley, 2521 Hearst Ave, Berkeley, CA 94709, USA \\
\and $^{3}$ The University of Wisconsin-Madison, 1415 Engineering Drive, Madison, WI 53706, USA

}

\email{bates26@llnl.gov}

%%%% packages and definitions (optional)
\usepackage{graphicx} 

% allows inclusion of graphics
\usepackage{booktabs} 

% nice rules (thick lines) for tables
\usepackage{microtype} 

% improves typography for PDF
\newcommand{\SN}{S$_N$} 
\renewcommand{\vec}[1]{\bm{#1}} 

%vector is bold italic
\newcommand{\vd}{\bm{\cdot}} 

% slightly bold vector dot
\newcommand{\grad}{\vec{\nabla}} 

% gradient
\newcommand{\ud}{\mathop{}\!\mathrm{d}} 

% upright derivative symbol
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

PyNE is a suite of free and open source (BSD licensed) tools to aid in computational nuclear science and engineering. PyNE seeks to provide native implementations of common nuclear algorithms, as well as Python bindings and I/O support for industry standard nuclear codes. In the past year, the PyNE development team has improved PyNE's ease of use by making binaries available for Windows, Mac, and Linux through the conda package manager and adding Python 3 support. PyNE has also added many features a including rigorous 2-step activation workflow \cite{Biondo2014}, PyDAGMC integration, CADIS variance reduction, and expanded ENSDF parsing support. As a part of our ongoing efforts to implement a verification and validation framework we also added continuous integration using the Build and Test Lab at the University of Wisconsin.

\section{Lowering the barrier to entry}

At our first PyNE workshop the development team was made painfully aware of the need to codify and simplify the install process. This lead to a concerted effort to both improve our install instructions and develop a binary distribution of PyNE. The core of this effort is based around the conda package manager. Conda is an open source package manager developed for Anaconda that is capable of managing packages on windows, mac and linux. This makes it possible to use a single package manager across all platforms. We developed a standard conda package script which can be found at https://github.com/conda/conda-recipes. This makes it possible to have a sure method of building and install PyNE on mac and linux for new users. In addition we used this tool to produce binary packages on linux and mac. Finally, we developed a custom windows build environment to build a distributable windows binary.

\subsection{Future proofing PyNE}

PyNE was originally developed for the Python 2 interpreter as it was, and still is the most common version of Python in scientific computing. Python 3 is slowly starting to replace it however as the default Python version. With this changeover on the horizon the PyNE development team made effort in preparation for the 0.4 release to make PyNE compatible with both versions. PyNE is now built and tested on Python 3 on a regular basis.

\section{Feature Enhancements}

\subsection{Mesh}

% (The writting of the ANS 2013W paper pre-dated the Mesh class, so we need to talk about this)
%
% Most of the cool stuff was implemented by Anthony ...
% - Materials on mesh
% - Pythonic access to data stored on iMesh tags, material objects: slicing, fancy indexing, boolean masking.
%
% cite:
% Mesh Oriented datABase (MOAB) \cite{tautges_moab:_2004}
% PyTAPS the Python interface the MOAB implimentation of ITAPS \cite{pytaps}

\subsection{DAGMC integration}

Direct Accelerated Geometry Monte Carlo (DAGMC) is a component of MOAB that
facilitates Monte Carlo ray tracing on CAD geometries
\cite{tautges_acceleration_2009}.  A \texttt{dagmc} module has been added to
PyNE, providing a Python interface to these ray tracing capabilities. The
\texttt{dagmc.discretize\_geom()} function accomplishes the common task of
mapping geometry cells onto Cartesian or tetrahedral mesh. The
\texttt{cell\_fracs\_to\_mats} to method of the \texttt{Mesh} class can be used
to seamlessly create PyNE \texttt{Mesh} objects tagged with materials, where the
materials are mixtures of the contributions from the various geometry cells
found in each mesh volume element. This especially useful for discretizing CAD
geometries onto grids for deterministic methods.

% If we need images, I could add a teapot-esque example. Though if we feel the
% teapot is getting trite I can do a different model. Ostensible a PyNE tree:
% http://grabcad.com/library/tree--4


\subsection{ALARA module}


\subsection{R2S Activation Workflow}

The Rigorous Two-Step (R2S) method is used to estimate the shutdown dose rate
(SDDR) in fusion systems from photons born from neutron activation products
\cite{chen_rigorous_2002}. This method involves seperate neutron and photon
transport simulations, coupled to a dedicated nuclear inventory analysis code.
The PyNE \texttt{R2S} module impliments a mesh-based R2S method and
accomplishes this coupling in-memory by leveraging the PyNE \texttt{mesh},
\texttt{material}, \texttt{dagmc}, \texttt{mcnp}, and \texttt{alara} modules.
The \texttt{R2S} module currently only supports transport with MCNP and nuclear
inventory analysis with ALARA \cite{wilson_validation_1998}, but support for
addtional physics codes is planned. 

... Mesh-based photon source sampling is accomplished within MCNP by compiling MCNP against...
% Not sure the best way to say this. Compile against pyne.so I guess? but it comes from source_sampling.cpp.


\subsection{Source Sampling}

%Elliott has not finished unit testing the Sampling module, but this remains a
%high priority. Not sure if I want to go into detail because it is about to get a
%huge facelift.

\subsection{CADIS variance reduction}

The Consistant Adjoint-Weighted Importance Sampling (CADIS) and the
Forward-Weighted CADIS (FW-CADIS) method are a hybrid MC variance reduction
techniques that use determinstic estimates of the forward and adjoint flux to
generate MC weight windows and source biasing parameters
\cite{haghighat_monte_2003}. A mesh-based implimentation of this method has
been added to the PyNE \texttt{variancereduction} module. Work is currently
underway to interface with the Denovo \cite{Denovo} deterministic transport
code to in order to acquire these determinsitic fluxes.

% need add Denovo reference to .bib

\subsection{Tally Class}

\subsection{Fluka Module}

\subsection{Future work}
- unified DAGMC workflow
- AHOT
- multi-step CADIS MCVR

\subsection{other stuff?}

\subsection{Amalgamation}

While PyNE is ostensibly a Python oriented toolkit over two-thirds of the codebase is written in C++. This makes it possible to use many of the features of PyNE without needing Python. In order to simplify the use of PyNE's C++ API we have added the ability to amalgamate all of the C++ code into a single source and header file. This makes it possible to just add these two files to any project in order to use much of the functionality in PyNE without having to worry about linking multiple libraries in a seperate location. This is used in Cyclus (http://fuelcycle.org) to use PyNE features without adding a dependency on python.

\subsection{ENSDF Improvements}

Previous versions of PyNE have included some limited ENDF parsing capabilities. These have been focused on extracting half lives and branching ratios of metastable and ground states. This has been vastly expanded to support the parsing of most ENSDF record types and to make level structure and decay data available in PyNE's C++/Python nuclear data interface. This makes it possible to use PyNE to look up decay data, similar to what can be done with nudat2. 

We have broken down the data from ENSDF into six distinct subsets. These include: excited level data, decay normalization data, gamma-ray data, alpha decay data, $\beta^-$ decay, and electron capture/$\beta^+$ decay. In addition to information about the radiations for all decay transitions listed in ENSDF we have also included atomic data from NNDC to calculate X-ray emmissions from conversion electrons in gamma ray emmission and electron capture/$\beta^+$ decay.

\subsection{Fission Yield data}

The latest release of PyNE includes two different sets of fission yield data. The first is the IAEA WIMSD library which provides fission product yields based on ENDF/B-VI. The second is from the IAEA Safeguards data library and includes independent fission yields with thermal, fast, and 14-MeV neutrons for $^{232}$Th, $^{233}$U, $^{235}$U, $^{239}$Pu, and $^{241}$Pu.

\section{Verification and Validation}

This issue will be addressed in more detail in other concurrent publications but the PyNE development team is working to implement documented verification and validation as a part of our basic development process. This has included: ensuring all code changes to PyNE have at least one reviewer who was not an author, tests of all code additions, a coding style guide, requiring all tests to pass on continuous integration builds before merging code changes. 

\section{Cultivation of Users and Developers} 
Computational toolkits in the sciences grow more robust by a broad user base who tests core capabilities with each use. Similarly, such toolkits grow more powerful by a broad developer base that serves the community by contributing new, research-relevant features. Development of a sustainable user and developer community is therefore integral to the success of the PyNE toolkit. To this end, the development team has organized tutorials to reach out to new users and has sought out support development by graduate students.

A tutorial at the University of California Berkeley was organized in <November?> to both reach out to new users and to gather feedback on the user experience of PyNE. Over a dozen researchers attended. The audience included undergraduate and graduate students in nuclear engineering as well as postdoc and faculty. In a six hour workshop, the attendees installed PyNE and ran prepared examples with the help of members of the development team. In addition to demonstrating the core data manipulation capabilities of the PyNE toolkit, the workshop included a reflective period in which attendees had the opportunity to spbrainstorm and suggest extensions, features, and improvements for the toolkit that were of interest in the context of their particular research. We learned from this experience <discussion-of-installation-push>.

Based on the success of this event and the organic growth of our user base, a second user workshop will be conducted at RPSD. <insert-discussion-of-expectations>.

The development team has also conducted  development both UCBerkeley and the University of Wisconsin to cultivate the developer communities that have arisen in those institutions. These sprints allow the diverse and geographically dispersed development team to gather and collaborate on code contributions in a coherent manner. 

In order to encourage young researchers to become involved in scientific computing, a number of desired PyNE extensions have been defined online. These short descriptions of desired extensions can be found on the PyNE website and are intended to guide the contributions of young researchers. By defining relevant independent contributions with realistic scope, these descriptions provide an opportunity for a beginner developer to contribute code in a guided manner and will assist their transition from user to developer. 

\section{Conclusions}

In the past year the PyNE development team has worked to improve PyNE's usability in addition to adding new features. The availability of binaries for stable releases has made PyNE more accessible to those who are users but not developers. The PyNE project will continue to create free and open source tools that easily interface the plethora of choices available in nuclear engineering and scientific computing. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{ans} 
\bibliography{bibliography} \end{document}
